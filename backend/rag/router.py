"""ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ (DB / RAG / Web 3ë‹¨ ë¼ìš°íŒ…)"""
import json
import logging
import re
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from rag.config import OPENAI_API_KEY, get_settings
from rag.db_query import query_db
from rag.chain import query_rag, query_rag_stream
from rag.web_search import query_web
from rag.vector_store import search_similar

logger = logging.getLogger(__name__)

# â”€â”€ í‚¤ì›Œë“œ í”„ë¦¬ì²´í¬ (LLM í˜¸ì¶œ ì—†ì´ ì¦‰ì‹œ ì‘ë‹µ) â”€â”€

_WIFI_PATTERN = re.compile(r"ì™€ì´íŒŒì´|wifi|wi-fi|ì™€ì´íŒŒì´\s*ë¹„ë²ˆ|ì™€ì´íŒŒì´\s*ë¹„ë°€ë²ˆí˜¸", re.IGNORECASE)

def _keyword_precheck(question: str) -> dict | None:
    """í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¦‰ì‹œ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ê°ì§€"""
    if _WIFI_PATTERN.search(question):
        return {
            "answer": "ì™€ì´íŒŒì´ QRì½”ë“œì…ë‹ˆë‹¤! ì¹´ë©”ë¼ë¡œ ìŠ¤ìº”í•´ì£¼ì„¸ìš” ğŸ“±",
            "image": "/images/wifi-qr.png",
            "route": "keyword",
        }
    return None


CLASSIFIER_SYSTEM = """ë‹¹ì‹ ì€ ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ "db" ë˜ëŠ” "rag" ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.
ì´ì „ ëŒ€í™” ë§¥ë½ì´ ìˆìœ¼ë©´ ì°¸ê³ í•˜ì„¸ìš”.

"db" â€” ì•„ë˜ í…Œì´ë¸”ì—ì„œ ì¡°íšŒí•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸:
  - profiles í…Œì´ë¸”: ì§ì› ì´ë¦„(username), ë¶€ì„œ(department), ì§ê¸‰(position), ë¶„ì•¼(field)
    ë¶€ì„œ: AI, ê²½ì˜, ê¸°íš, ì„œë¹„ìŠ¤ê°œë°œ, ì—°êµ¬ì†Œ
    ì§ê¸‰: CEO, CTO, ëŒ€ë¦¬, ë¶€ì†Œì¥, ì‚¬ì›, ì†Œì¥, ì—°êµ¬ì›, ì´ì‚¬, íŒ€ì¥
    ì˜ˆ: "íŒ€ì¥ ëˆ„êµ¬ì•¼?", "ëª‡ ëª…ì´ì•¼?", "ì„œë¹„ìŠ¤ê°œë°œíŒ€ ëˆ„êµ¬ ìˆì–´?", "ëŒ€í‘œ(=CEO) ëˆ„êµ¬ì•¼?", "ì „ë³‘í›ˆì´ ë­í•˜ëŠ” ì‚¬ëŒì´ì•¼?", "AIíŒ€ì— ì‚¬ì› ëˆ„êµ¬?"
    â€» "ëŒ€í‘œ"â†’"CEO", "ê°œë°œíŒ€"â†’"ì„œë¹„ìŠ¤ê°œë°œ" ë“± ì‚¬ìš©ì í‘œí˜„ì„ DB ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”
  - cafeteria_menus í…Œì´ë¸”: ì‹ë‹¹ ë©”ë‰´, ì ì‹¬, ì‹ë‹¨í‘œ
    ì˜ˆ: "ì˜¤ëŠ˜ ì ì‹¬ ë­ì•¼?", "ë‚´ì¼ ë©”ë‰´ëŠ”?"

"rag" â€” ìœ„ DBì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ëª¨ë“  ì§ˆë¬¸ (íšŒì‚¬ ë¬¸ì„œ, ì¼ë°˜ ì§ˆë¬¸ ë“±)

ì¤‘ìš”: íŠ¹ì • ì‚¬ëŒ ì´ë¦„ì´ ì–¸ê¸‰ë˜ë©´ ë¬´ì¡°ê±´ "db"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:
{{"intent": "db ë˜ëŠ” rag", "table": "profiles ë˜ëŠ” cafeteria_menus(dbì¼ ë•Œ)", "filters": {{"position": "ê°’", "department": "ê°’", "username": "ê°’", "day": "ì›”/í™”/ìˆ˜/ëª©/ê¸ˆ/ë‚´ì¼/ëª¨ë ˆ"}}}}
filtersì—ëŠ” ì§ˆë¬¸ì—ì„œ ì¶”ì¶œí•œ ì¡°ê±´ë§Œ ë„£ìœ¼ì„¸ìš”. ì‚¬ìš©ì í‘œí˜„ì„ DB ê°’ìœ¼ë¡œ ë³€í™˜í•´ì„œ ë„£ìœ¼ì„¸ìš”. ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´ {{}}."""


def _build_classifier_messages(question: str, history: list[dict] | None = None) -> list:
    """ë¶„ë¥˜ê¸°ìš© ë©”ì‹œì§€ êµ¬ì„± (ëŒ€í™” ë§¥ë½ í¬í•¨)"""
    msgs = [("system", CLASSIFIER_SYSTEM)]
    for h in (history or [])[-4:]:
        role = "human" if h["role"] == "user" else "assistant"
        msgs.append((role, h["content"]))
    msgs.append(("human", question))
    return ChatPromptTemplate.from_messages(msgs).format_messages()


async def _classify(question: str, history: list[dict] | None = None) -> dict:
    """ì§ˆë¬¸ ë¶„ë¥˜ â†’ {"intent": "db|rag", "table": ..., "filters": {...}}"""
    settings = get_settings()
    llm = ChatOpenAI(
        model=settings["chat_model"],
        temperature=0,
        openai_api_key=OPENAI_API_KEY,
    )
    try:
        messages = _build_classifier_messages(question, history)
        response = llm.invoke(messages)
        result = json.loads(response.content)
        logger.info(f"ì§ˆë¬¸: '{question}' â†’ ë¶„ë¥˜: {result}")
        return result
    except Exception as e:
        logger.warning(f"ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨, RAGë¡œ í´ë°±: {e}")
        return {"intent": "rag"}


_RAG_SIMILARITY_THRESHOLD = 0.35


async def classify_and_route(question: str, history: list[dict] | None = None) -> dict:
    """ì§ˆë¬¸ì„ ë¶„ë¥˜í•˜ê³  ì ì ˆí•œ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¼ìš°íŒ… (DB â†’ RAG â†’ Web í´ë°±)"""
    pre = _keyword_precheck(question)
    if pre:
        return pre

    c = await _classify(question, history)
    intent = c.get("intent", "rag")

    if intent == "db":
        result = await query_db(c.get("table", ""), c.get("filters", {}))
        result["route"] = "db"
        return result

    # RAG: ë¬¸ì„œ ìœ ì‚¬ë„ í™•ì¸ í›„, ë‚®ìœ¼ë©´ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
    try:
        settings = get_settings()
        docs = search_similar(question, k=settings["retrieval_k"])
        best_score = max((d.get("similarity", 0) for d in docs), default=0)

        if docs and best_score >= _RAG_SIMILARITY_THRESHOLD:
            result = await query_rag(question, history=history, docs=docs)
            result["route"] = "rag"
            return result

        logger.info(f"RAG ìœ ì‚¬ë„ ë‚®ìŒ (best={best_score:.3f}), ì›¹ ê²€ìƒ‰ í´ë°±")
    except Exception as e:
        logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨, ì›¹ ê²€ìƒ‰ í´ë°±: {e}")

    try:
        result = await query_web(question)
        result["route"] = "web"
        return result
    except Exception as e:
        logger.warning(f"ì›¹ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {e}")
        return {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤, ì§€ê¸ˆì€ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "route": "error"}


async def classify_and_route_stream(question: str, history: list[dict] | None = None):
    """ìŠ¤íŠ¸ë¦¬ë° ë¼ìš°íŒ…: DB â†’ RAG â†’ Web í´ë°± ì²´ì¸"""
    pre = _keyword_precheck(question)
    if pre:
        yield {"type": "tag_result", "data": pre}
        return

    c = await _classify(question, history)
    intent = c.get("intent", "rag")

    if intent == "db":
        result = await query_db(c.get("table", ""), c.get("filters", {}))
        result["route"] = "db"
        yield {"type": "tag_result", "data": result}
        return

    # RAG: ë¬¸ì„œ ìœ ì‚¬ë„ í™•ì¸ í›„, ë‚®ìœ¼ë©´ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
    try:
        settings = get_settings()
        docs = search_similar(question, k=settings["retrieval_k"])
        best_score = max((d.get("similarity", 0) for d in docs), default=0)

        if docs and best_score >= _RAG_SIMILARITY_THRESHOLD:
            yield {"type": "route_info", "route": "rag"}
            async for event in query_rag_stream(question, history=history, docs=docs):
                yield event
            return

        logger.info(f"RAG ìœ ì‚¬ë„ ë‚®ìŒ (best={best_score:.3f}), ì›¹ ê²€ìƒ‰ í´ë°±")
    except Exception as e:
        logger.warning(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨, ì›¹ ê²€ìƒ‰ í´ë°±: {e}")

    try:
        result = await query_web(question)
        result["route"] = "web"
        yield {"type": "tag_result", "data": result}
    except Exception as e:
        logger.warning(f"ì›¹ ê²€ìƒ‰ë„ ì‹¤íŒ¨: {e}")
        yield {"type": "tag_result", "data": {"answer": "ì£„ì†¡í•©ë‹ˆë‹¤, ì§€ê¸ˆì€ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.", "route": "error"}}
